PHASE 5 — Structured Rule Editor UI & Admin Tools (Conceptual, Implementation-Ready Instructions)

Goal
Give admins a safe, auditable, easy-to-use interface to view, edit, version, test, and publish machine-readable policy_rules without rerunning the LLM. Make rule edits deterministic, validated, and previewable so production evaluations remain stable.

This doc describes WHAT to build, WHY, and exactly HOW it should behave (no code). Use it as the product spec for frontend, backend, QA, and ops.

1 — Core principles (non-negotiable)

Never allow ambiguous rules. Every saved rule must meet the structured schema.

Two-stage publishing. Edits create a draft; publish is explicit and audited.

Preview before publish. Sandbox-run the rule engine on sample transcripts.

Versioning & rollback. Every publish creates an immutable version with diff and hash.

Least privilege. Only admins/policy owners can publish; reviewers can draft.

Deterministic outcomes. Editor changes produce deterministic rule JSON; UI shows exact consequences.

Safety w/ critical rules. Publishing changes that flip critical=true requires secondary confirmation (2-step).

Audit trail. Who changed what, when, why — immutable.

2 — Primary screens & flows (UX)
A. Policy Rule Editor (main)

Header: Policy Template name, Current rules_version, last_published_by + timestamp.

Top bar: Actions — Save Draft, Preview (Sandbox), Publish, Discard Draft, History.

Left column: Category accordion (Professionalism, Empathy, Resolution, custom categories).

Main pane: Rule list for selected category (sortable by severity / id / status).

Rule row: id, short description, type badge (boolean/numeric/list/conditional/multi-step), severity, enabled toggle, edit button, evidence examples link.

“Add Rule” button opens guided wizard (see below).

Inline validation errors shown as modals or tooltips.

B. Rule Edit / Add Wizard

Step 1: Select Rule Type (boolean / numeric / list / conditional / multi-step).

Step 2: Fill required fields:

id (auto-suggest sanitized slug)

human-friendly label

category (dropdown)

severity (minor/moderate/major/critical)

enabled (checkbox)

description (for humans only)

evidence pattern (examples or phrase patterns)

Step 3: Rule-specific inputs:

boolean → required=true/false, evidence phrases (multi-line), time window (optional)

numeric → comparator (le/lt/ge/gt/eq), numeric value, unit (seconds)

list → items to require

conditional → if-then structure (condition builder: e.g., if caller_sentiment <= -0.4 then requires apology_phrases)

multi-step → ordered checklist with required order flag

Step 4: Preview of normalized JSON rule (read-only) with “What this will catch” examples auto-generated.

Step 5: Save to draft.

C. Drafts & History Screen

List of drafts (id, author, created_at, status: editing|needs_clarification|ready_for_confirm|validation_failed|failed).

Version history: list of published versions with diff viewer.

Rollback action creates a new draft to confirm rollback before publish.

D. Sandbox / Preview Panel

Select sample transcripts (org-provided fixtures or user-uploaded anonymized snippet) to run RuleEngineV2 against the draft rules.

Show:

rule-by-rule pass/fail + evidence snippets

aggregate category-level penalties and expected rubric impacts (estimated)

warning flags for critical failures

Rate-limited (per-org quotas).

E. Clarification Q&A Panel

If rules were generated by Policy Rule Builder and contain clarifications, show question list, current answers, and edit boxes.

Track answered_by, answered_at.

Allow re-run generator (if enabled) or manual edit.

3 — Validation & UX safeguards
A. Real-time validation

Use JSON Schema on client and server to ensure immediate feedback.

Show clear human-readable error strings (e.g., “Numeric rule requires comparator: le, lt, ge, gt, eq”).

B. Prevent dangerous publishes

Publishing a draft that enables/changes a critical rule must show a modal requiring: reason for change (text), 2nd approver confirmation (if org policy), and produces an audit note.

If a published change increases the potential penalty > threshold (configurable), require staged rollout or test-run.

C. Preview evidence examples

For each rule show 2–3 synthetic or sampled transcript snippets that would trigger the rule (auto-generated based on patterns). Helps admins understand behavior.

D. Inline help & tooltips

Each field has short help text explaining what to enter and implications.

Provide “why this matters” callouts for severity and critical flags.

4 — Permissions & governance model
Roles

Policy Admin — create/confirm/publish/rollback rules. Full access.

Policy Editor/Reviewer — can draft, sandbox, comment, but cannot publish.

Audit Viewer — readonly access to history and evidence.

Super Admin — system-level controls (feature flags, global quotas).

Approvals

Optionally require 2-step approval: Author submits draft → Reviewer approves → Publish.

Configurable per org (enterprise customers can mandate approval workflows).

Audit

Every action records: user_id, ip, timestamp, delta (diff), reason (optional), rules_hash, draft_id/version_id, whether change was LLM-generated or manual.

5 — Sandbox & testing
Sandbox behavior

Runs rule engine only (no LLM).

Returns deterministic policy_results.

Shows exact penalties and expected rubric downgrades but not final numeric scores (scoring only occurs in production pipeline).

Limit sandbox runs per org/day and per user to control resource usage.

Test transcripts

Provide sample transcripts library per org: normal, edge-case, angry caller, silence heavy, escalation heavy.

Allow admins to upload a small anonymized transcript to test a draft.

6 — Versioning, release & rollback
Version artifact

Each published version is immutable and includes:

rules_json

rules_hash (SHA256)

created_by, created_at

llm_generated_flag (true/false)

rules_version (sequential)

Rollback

Rollback must create a new draft set to the target version’s rules (never mutate historical versions).

Require publish to make rollback active (confirmation required).

Migration note

If a new ruleset changes existing behavior drastically, make a “staged publish” option: preview runs for a test cohort before global application.

7 — Observability & metrics (what to monitor)

Track per-org and global:

drafts created / published
sandbox runs (per org/user)

% published changes that cause critical flags

avg time draft → publish

validation failure rate

rollback rate

admin approval time

rule usage (how often a rule fires across evaluations)

top firing rules and top failing rules

percentage LLM-generated rules vs manual

Alerts:

sudden spike in published critical rules

high sandbox failure rate (indicates ambiguous rules)

abuse detection (excessive sandbox runs)

8 — Security, privacy & compliance

Mask/download redaction:

UI never shows raw PII from real transcripts in default mode. Sandbox test uploads must be explicitly labeled and redacted unless admin confirms otherwise.

Access control:

Only authorized roles can view/edit/publish.

Data retention:

Keep versions and audit logs immutable for required retention periods.

Encryption & keys:

Rules and versions stored encrypted at rest. Only necessary services can decrypt.

9 — Usability, onboarding & documentation
Onboarding

Guided tour for first-time users: explain difference between human policy text and structured rules; show sample sandbox run.

Pre-populate common rule templates for onboarding (greeting, verification, apology, hold behavior).

Documentation

In-app “What this rule does” and link to full docs.

Example catalog: common patterns + expected evidence snippets.

Admin quick-start: how to test and publish safely.

Training

Provide short training materials for admins: checklist to validate rules, common pitfalls, and governance best practices.

10 — Edge cases & fallbacks
Edge: conflicting rules

If two rules conflict (e.g., one requires escalation, another forbids escalation), editor warns on save and prevents publish until conflict resolved.

Edge: missing coverage

If draft introduces a situation with no rule coverage (system detects gap relative to common patterns), show “coverage gap” warning and recommend generator suggestions.

Edge: LLM-generated rules with low confidence

Mark rules that were auto-generated with a confidence score. Low-confidence rules should require explicit admin confirmation.

11 — Accessibility & internationalization

Accessible controls (keyboard navigable, ARIA labels).

Localize UI strings and help text (support PH/EN by default; allow org to provide translations for rule labels).

Numeric formats and time units must be locale-aware.

12 — Testing & QA checklist (before rollout)

UI validation for every rule type and failure path.

Sandbox end-to-end tests with sample transcripts.

Permission tests: publish, edit, rollback as different roles.

Load tests: many concurrent admins and sandbox runs.

Security tests: audit log integrity, RBAC enforcement.

Usability testing with 3–5 policy admins (pilot customers).

13 — Rollout plan (recommended)

Internal alpha — Ship to platform internal users only; collect feedback. (enable_rule_editor_ui=false)

Pilot — 2–3 customers with hand-holding; add sample policies.

Gradual rollout — enable per-org via feature flag; monitor metrics for 2 weeks.

GA — enable globally once stable.

Require explicit communications to customers about behavior changes and training materials.

14 — Deliverables (for product + design + engineering hand-off)

UI mockups / wireframes: Editor main, Wizard steps, Sandbox, History, Draft list.

UX copy for every control + validations.

Acceptance criteria for each screen.

List of sample transcripts for sandbox.

Admin onboarding checklist.

Monitoring dashboards and alert rules.

Audit schema and retention policy.

Rollout & pilot playbook.

15 — Final checklist (actionable)

 Design wireframes and microcopy

 Implement client-side schema-driven forms & validation

 Implement draft/publish flow with audit capture

 Implement sandbox integration with RuleEngineV2 (deterministic)

 Add versioning + rollback UI

 Add RBAC, 2-step publish for critical rules

 Add metrics, logs, and alerts

 Pilot with internal + 2 customers, iterate

 Global rollout and deprecate manual LLM rule edits